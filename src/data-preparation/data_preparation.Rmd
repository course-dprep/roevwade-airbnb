---
title: "Data preparation"
output: html_document
date: '2022-09-18'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
## Load packages
library(dplyr)
library(googlesheets4)

## Importing Google Sheet as CSV in R. 
gs4_deauth()
df <- read_sheet("https://docs.google.com/spreadsheets/d/1tOMjx-lflqp-9XC1iGc9tdBIfK-nrOdlsLnFGgLFdVA/edit#gid=0")
df 
head(df)
before_url <- as.character(df$before_url)
after_url <- as.character(df$after_url)
```


```{r}
## Reading datasets for all cities 
tbl <- lapply(before_url, function(before_url) {
  print(paste0('Now downloading ... ', before_url))
  d <- read.csv(before_url)
  city = tolower(as.character(df$city[match(before_url, df$before_url)]))
  d$city <- city
  states = as.character(df$states[match(before_url, df$before_url)])
  d$states <- states
  return(d)
})

```
```{r}
## Reading datasets for all countries
tbl <- lapply(after_url, function(after_url) {
  print(paste0('Now downloading ... ', after_url))
  d <- read.csv(after_url)
  city = tolower(as.character(df$city[match(after_url, df$after_url)]))
  d$city <- city
  states = as.character(df$states[match(after_url, df$after_url)])
  d$states <- states
  return(d)
})
### note: some of the after urls are not available in the inside aribnb website now, so it cannot run because there are some NAs, is this code right?
```

```{r}
## Combining data into a single data frame
combined_data = do.call('rbind', tbl)
head(combined_data)
glimpse(combined_data)

data[[1:31]]$time<-0
data[[32:62]]$time<-1

data1 <- lapply(data, function(x) x %>% group_by(host_id)%>%summarise(price,time)) %>% bind_rows()

## Writing data into csv file and creating directory if nonexistent
if (!dir.exists("../../gen")) {
  dir.create("../../gen")
} else {
  print("Directory already exists!")
}

if (!dir.exists("../../gen/temp")) {
  dir.create("../../gen/temp")
} else {
  print("Directory already exists!")
}
write.csv(combined_data,
          paste0("../../gen/temp/combined_city_data.csv"),
          row.names = F)

```




```{r}
## original code

urls = c('http://data.insideairbnb.com/united-states/ny/new-york-city/2022-06-03/visualisations/listings.csv', 'http://data.insideairbnb.com/united-states/ny/new-york-city/2022-09-07/visualisations/listings.csv')

data <- lapply(urls, read.csv) # lower case variable names, use "general variable names" (e.g., df, data)
```

```{r}
##
data[[1]]$time<-0
data[[2]]$time<-1

data1 <- lapply(data, function(x) x %>% group_by(host_id)%>%summarise(price,time)) %>% bind_rows()

## still need a column "state" and a column "city" (how to automate this process?)
```


```{r}

```

